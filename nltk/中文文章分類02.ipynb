{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 給予文章內容\n",
    "2. 對於每篇文章給予分類: A,B,C\n",
    "3. 建立＆測試模型\n",
    "4. 預測分類\n",
    "5. 預測率太低的處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB #導入多項式貝葉斯算法\n",
    "from sklearn import metrics\n",
    "import jieba\n",
    "\n",
    "# from __future__ import print_function, unicode_literals\n",
    "# import os\n",
    "filepath=\"../data/zh_dic.txt\"\n",
    "jieba.load_userdict(filepath)\n",
    "\n",
    "# Bunch類提供一種key,value的對象形式\n",
    "# target_name:所有分類集名稱列表\n",
    "# label:每個文件的分類標籤列表\n",
    "# filenames:文件路徑  ==> 這是使用檔案形式才需要的\n",
    "# contents:分詞後文件詞向量形式\n",
    "bunch = Bunch(target_name=[],label=[],contentnames=[],contents=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if os.path.isfile(filepath):\n",
    "#     jieba.load_userdict(filepath)\n",
    "# import jieba.posseg as pseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training data - news data\n",
    "onews1 = \"藝人, 八卦，音樂,歌劇,愛不愛\"\n",
    "onews2 = \"當年九把刀劈腿曝光後，曾在記者會上表明雖然自己2個都很喜歡，不只周亭羽也愛小內，但仍把希望放在正宮小內身上\"\n",
    "onews3 = \"中國共產黨第十九次全國代表大會今（18）日揭幕，一連7天在北京人民大會堂舉行，外界關注中共總書記習近平的第二個5任期，可能確立個人集權。對此，前政大國發所所長李酉潭直言，習近平已經無路可走，若不將中共實施民主化會很慘。李酉潭指出，中國大陸政權的領導方式，從鄧小平之後都走集體領導，如今要走回全部權力集中，黨內會有更大反撲；政治學有一個定理，「擁有權力會腐化，擁有絕對的權力會絕對的腐化」，就算習近平不腐化，權力在手中，別人巴不得去巴結，如何避免旁邊的人不腐化？\"\n",
    "onews4 = \"於1981年起擔任中國駐聯合國日內瓦辦事處譯員，1987年進入中國外交部國際司\"\n",
    "onews5 = \"NBA, 三巨頭55分 雷霆拒絕被逆轉,三分火炮穩住軍心\"\n",
    "onews6 = \"NBA,詹姆斯歸隊 騎士仍不敵公牛吞4連敗,每場輸對手10.5分，可見得整個球隊還處在磨合期\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中國共產黨 第十九次 全國代表大會 今 （ 18 ） 日 揭幕 ， 一連 7 天在 北京人民大會堂 舉行 ， 外界 關注 中共 總書記 習近平 的 第二個 5 任期 ， 可能 確立 個人 集權 。 對此 ， 前 政大 國發 所 所長 李酉潭 直言 ， 習近平 已經 無路可走 ， 若不將 中共 實施 民主化 會 很慘 。 李酉潭 指出 ， 中國 大陸 政權 的 領導 方式 ， 從 鄧小平 之後 都 走 集體領導 ， 如今 要 走 回 全部 權力 集中 ， 黨內 會 有 更 大 反撲 ； 政治學 有 一個 定理 ， 「 擁有 權力 會 腐化 ， 擁有 絕對 的 權力 會 絕對 的 腐化 」 ， 就算 習近平 不 腐化 ， 權力 在 手中 ， 別人 巴不得 去 巴結 ， 如何 避免 旁邊 的 人 不 腐化 ？\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(onews3, cut_all=False)\n",
    "# print \"Default Mode:\", \" \".join(seg_list)  # 預設模式\n",
    "print \" \".join(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news1 = \" \".join(jieba.cut(onews1, cut_all=False))\n",
    "news2 = \" \".join(jieba.cut(onews2, cut_all=False))\n",
    "news3 = \" \".join(jieba.cut(onews3, cut_all=False))\n",
    "news4 = \" \".join(jieba.cut(onews4, cut_all=False))\n",
    "news5 = \" \".join(jieba.cut(onews5, cut_all=False))\n",
    "news6 = \" \".join(jieba.cut(onews6, cut_all=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "構建文本對象結束！！！\n"
     ]
    }
   ],
   "source": [
    "labelList = np.array(['a','b','c'])\n",
    "bunch.target_name.extend(labelList)\n",
    "# for mylabel in labelList:\n",
    "bunch.label.append(labelList[0])\n",
    "bunch.contents.append(news1)\n",
    "bunch.contentnames.append(\"news1\")\n",
    "bunch.label.append(labelList[0])\n",
    "bunch.contents.append(news2)\n",
    "bunch.contentnames.append(\"news2\")\n",
    "bunch.label.append(labelList[1])\n",
    "bunch.contents.append(news4)\n",
    "bunch.contentnames.append(\"news4\")\n",
    "bunch.label.append(labelList[1])\n",
    "bunch.contents.append(news3)\n",
    "bunch.contentnames.append(\"news3\")\n",
    "bunch.label.append(labelList[2])\n",
    "bunch.contents.append(news5)\n",
    "bunch.contentnames.append(\"news5\")\n",
    "bunch.label.append(labelList[2])\n",
    "bunch.contents.append(news6)\n",
    "bunch.contentnames.append(\"news6\")\n",
    "\n",
    "#對象持久化                                                                                              \n",
    "file_obj = open(\"train_set.dat\", \"wb\")\n",
    "pickle.dump(bunch,file_obj)                      \n",
    "file_obj.close()\n",
    "\n",
    "print \"構建文本對象結束！！！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if-idf詞向量空間創建成功！！！\n"
     ]
    }
   ],
   "source": [
    "#引入持久化類\n",
    "import cPickle as pickle\n",
    "from sklearn import feature_extraction  \n",
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "\n",
    "# 讀取文件\n",
    "def readfile(path):\n",
    "    fp = open(path,\"rb\")\n",
    "    content = fp.read()\n",
    "    fp.close()\n",
    "    return content\n",
    "\n",
    "#計算訓練語料的tfidf權值並持久化為詞袋\n",
    "\n",
    "#讀取bunch對象\n",
    "def readbunchobj(path):\n",
    "    file_obj = open(path, \"rb\")\n",
    "    bunch = pickle.load(file_obj) \n",
    "    file_obj.close()\n",
    "    return bunch\n",
    "\n",
    "#寫入bunch對象\n",
    "def writebunchobj(path,bunchobj):\n",
    "    file_obj = open(path, \"wb\")\n",
    "    pickle.dump(bunchobj,file_obj) \n",
    "    file_obj.close()\n",
    "\n",
    "# 構建tf-idf詞向量空間對象\n",
    "tfidfspace = Bunch(target_name=bunch.target_name,label=bunch.label,contentnames=bunch.contentnames,tdm=[],vocabulary={})\n",
    "# 使用TfidfVectorizer初始化向量空間模型 \n",
    "stopword_path = \"hlt_stop_words.txt\"\n",
    "stpwrdlst = readfile(stopword_path).splitlines()\n",
    "vectorizer = TfidfVectorizer(stop_words=stpwrdlst,sublinear_tf = True,min_df =1, max_features=30)\n",
    "# vectorizer = TfidfVectorizer(stop_words=stpwrdlst,sublinear_tf = True,min_df =1,ngram_range=(1,2))\n",
    "transformer=TfidfTransformer() # 該類會統計每個詞語的tf-idf權值\n",
    "# 文本轉為詞頻矩陣,單獨保存字典文件 \n",
    "tfidfspace.tdm = vectorizer.fit_transform(bunch.contents)\n",
    "tfidfspace.vocabulary = vectorizer.vocabulary_\n",
    "\n",
    "# 創建詞袋的持久化\n",
    "space_path = \"tfdifspace.dat\"        # 詞向量空間保存路徑\n",
    "writebunchobj(space_path,tfidfspace)\n",
    "\n",
    "print \"if-idf詞向量空間創建成功！！！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'nba': 0,\n",
       " u'\\u4e2d\\u5171': 1,\n",
       " u'\\u4e2d\\u570b': 2,\n",
       " u'\\u64c1\\u6709': 3,\n",
       " u'\\u653f\\u6cbb\\u5b78': 4,\n",
       " u'\\u6574\\u500b': 5,\n",
       " u'\\u65b9\\u5f0f': 6,\n",
       " u'\\u65c1\\u908a': 7,\n",
       " u'\\u66dd\\u5149': 8,\n",
       " u'\\u674e\\u9149\\u6f6d': 9,\n",
       " u'\\u6b0a\\u529b': 10,\n",
       " u'\\u6b4c\\u5287': 11,\n",
       " u'\\u6b63\\u5bae': 12,\n",
       " u'\\u6b78\\u968a': 13,\n",
       " u'\\u6bcf\\u5834': 14,\n",
       " u'\\u6c11\\u4e3b\\u5316': 15,\n",
       " u'\\u706b\\u70ae': 16,\n",
       " u'\\u7121\\u8def\\u53ef\\u8d70': 17,\n",
       " u'\\u7403\\u968a': 18,\n",
       " u'\\u7576\\u5e74': 19,\n",
       " u'\\u76f4\\u8a00': 20,\n",
       " u'\\u78ba\\u7acb': 21,\n",
       " u'\\u78e8\\u5408\\u671f': 22,\n",
       " u'\\u7a69\\u4f4f': 23,\n",
       " u'\\u7b2c\\u4e8c\\u500b': 24,\n",
       " u'\\u7b2c\\u5341\\u4e5d\\u6b21': 25,\n",
       " u'\\u7d55\\u5c0d': 26,\n",
       " u'\\u7e3d\\u66f8\\u8a18': 27,\n",
       " u'\\u7fd2\\u8fd1\\u5e73': 28,\n",
       " u'\\u8150\\u5316': 29}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# count_vect = CountVectorizer(stop_words=stpwrdlst ,decode_error='ignore')\n",
    "# X_train_counts = count_vect.fit_transform(tfidfspace.vocabulary)\n",
    "# X_train_counts.shape\n",
    "\n",
    "tfidfspace.vocabulary\n",
    "# 三巨頭55分 : \\u4e09\\u5de8\\u982d55\\u5206\n",
    "# 表示斷詞不夠好. 需要建立 vocabulary 以及 token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 30)\n",
      "['a', 'a', 'b', 'b', 'c', 'c']\n"
     ]
    }
   ],
   "source": [
    "print tfidfspace.tdm.shape\n",
    "print tfidfspace.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.57735027,  0.57735027,  0.57735027,  1.        ,\n",
       "        0.13314239,  0.16236593,  0.27490942,  0.16236593,  0.34074314,\n",
       "        0.16236593,  0.16236593,  0.27490942,  0.16236593,  0.16236593,\n",
       "        0.16236593,  0.16236593,  0.38745291,  0.16236593,  0.27490942,\n",
       "        0.38745291,  0.27490942,  0.16236593,  0.50161301,  0.61171251,\n",
       "        0.61171251,  0.34430007,  0.4198708 ,  0.4198708 ,  0.4198708 ,\n",
       "        0.4198708 ,  0.4198708 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfspace.tdm.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create test data - news data\n",
    "tnews1 = \"藝人, 八卦，音樂,歌劇,愛不愛, 高什麼\"\n",
    "tnews2 = \"劈腿曝光,也愛小內，但仍希望, 當年九把刀劈腿曝光後，曾在記者會上表明雖然自己2個都很喜歡\"\n",
    "tnews3 = \"一連7天在北京人民大會堂舉行，外界關注中共總書記習近平的第二個5任期，可能確立個人集權。對此，前政大國發所所長李酉潭直言\"\n",
    "tnews4 = \"中國外交部國際司,於1981年起擔任中國駐聯合國日內瓦辦事處譯員\"\n",
    "tnews5 = \"NBA, 三巨頭55分 雷霆三分\"\n",
    "#tnews6 = \"NBA,詹姆斯不敵,磨合期\"       \n",
    "# 上面的測試文字，太短, 會有維度的問題\n",
    "# tnews1 = \"藝人, 八卦，音樂,歌劇,愛不愛\"\n",
    "# tnews2 = \"當年九把刀劈腿曝光後，曾在記者會上表明雖然自己2個都很喜歡，不只周亭羽也愛小內，但仍把希望放在正宮小內身上\"\n",
    "# tnews3 = \"台灣的政治，國台辦不負責，4名副主任排名依序為\"\n",
    "# tnews4 = \"於1981年起擔任中國駐聯合國日內瓦辦事處譯員，1987年進入中國外交部國際司\"\n",
    "# tnews5 = \"NBA, 三巨頭55分 雷霆拒絕被逆轉,三分火炮穩住軍心\"\n",
    "# tnews6 = \"NBA,詹姆斯歸隊 騎士仍不敵公牛吞4連敗,每場輸對手10.5分，可見得整個球隊還處在磨合期\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tnews1 = \" \".join(jieba.cut(tnews1, cut_all=False))\n",
    "tnews2 = \" \".join(jieba.cut(tnews2, cut_all=False))\n",
    "tnews3 = \" \".join(jieba.cut(tnews3, cut_all=False))\n",
    "tnews4 = \" \".join(jieba.cut(tnews4, cut_all=False))\n",
    "tnews5 = \" \".join(jieba.cut(tnews5, cut_all=False))\n",
    "#tnews6 = \" \".join(jieba.cut(tnews6, cut_all=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "構建文本測試set結束！！！\n"
     ]
    }
   ],
   "source": [
    "testbunch = Bunch(target_name=[],label=[],contentnames=[],contents=[])\n",
    "testbunch.target_name.extend(labelList)\n",
    "# for mylabel in labelList:\n",
    "testbunch.label.append(labelList[0])\n",
    "testbunch.contents.append(tnews1)\n",
    "testbunch.contentnames.append(\"tnews1\")\n",
    "testbunch.label.append(labelList[2])\n",
    "testbunch.contents.append(tnews2)\n",
    "testbunch.contentnames.append(\"tnews2\")\n",
    "testbunch.label.append(labelList[1])\n",
    "testbunch.contents.append(tnews4)\n",
    "testbunch.contentnames.append(\"tnews4\")\n",
    "testbunch.label.append(labelList[1])\n",
    "testbunch.contents.append(tnews3)\n",
    "testbunch.contentnames.append(\"tnews3\")\n",
    "testbunch.label.append(labelList[2])\n",
    "testbunch.contents.append(tnews5)\n",
    "testbunch.contentnames.append(\"tnews5\")\n",
    "#testbunch.label.append(labelList[2])\n",
    "#testbunch.contents.append(tnews6)\n",
    "#testbunch.contentnames.append(\"tnews6\")\n",
    "\n",
    "#對象持久化                                                                                              \n",
    "file_obj = open(\"test_set.dat\", \"wb\")\n",
    "pickle.dump(testbunch,file_obj)                      \n",
    "file_obj.close()\n",
    "\n",
    "print \"構建文本測試set結束！！！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test詞向量空間創建成功！！！\n"
     ]
    }
   ],
   "source": [
    "#test詞向量空間創建\n",
    "# 構建tf-idf詞向量空間對象\n",
    "testspace = Bunch(target_name=testbunch.target_name,label=testbunch.label,contentnames=testbunch.contentnames,tdm=[],vocabulary={})\n",
    "# 使用TfidfVectorizer初始化向量空間模型 \n",
    "stopword_path = \"hlt_stop_words.txt\"\n",
    "stpwrdlst = readfile(stopword_path).splitlines()\n",
    "vectorizer = TfidfVectorizer(stop_words=stpwrdlst,sublinear_tf = True,max_df = 0.5, max_features=30)\n",
    "# vectorizer = TfidfVectorizer(stop_words=stpwrdlst,sublinear_tf = True,min_df = 1, ngram_range=(1,2))\n",
    "\n",
    "# 補足不足處\n",
    "# from sklearn.feature_extraction.text import HashingVectorizer\n",
    "# hv = HashingVectorizer(n_features=23)\n",
    "\n",
    "\n",
    "transformer=TfidfTransformer() # 該類會統計每個詞語的tf-idf權值\n",
    "# 文本轉為詞頻矩陣,單獨保存字典文件 \n",
    "testspace.tdm = vectorizer.fit_transform(testbunch.contents)\n",
    "testspace.vocabulary = vectorizer.vocabulary_\n",
    "# 新增\n",
    "# testspace.tdm = hv.transform(testbunch.contents)\n",
    "\n",
    "# 創建詞袋的持久化\n",
    "space_path = \"testspace.dat\"        # 詞向量空間保存路徑\n",
    "writebunchobj(space_path,testspace)\n",
    "\n",
    "print \"test詞向量空間創建成功！！！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'c', 'b', 'b', 'c']\n",
      "(5, 30)\n",
      "[[ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.70710678\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.70710678  0.          0.          0.          0.\n",
      "   0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.31835597\n",
      "   0.31835597  0.          0.          0.          0.53902351  0.          0.\n",
      "   0.31835597  0.          0.          0.          0.          0.          0.\n",
      "   0.31835597  0.          0.          0.31835597  0.31835597  0.          0.\n",
      "   0.          0.31835597  0.        ]\n",
      " [ 0.5         0.          0.          0.          0.          0.          0.\n",
      "   0.          0.5         0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.5         0.\n",
      "   0.          0.          0.          0.          0.5         0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.28867513  0.          0.          0.\n",
      "   0.28867513  0.          0.28867513  0.          0.28867513  0.          0.\n",
      "   0.28867513  0.28867513  0.28867513  0.28867513  0.28867513  0.          0.\n",
      "   0.28867513  0.          0.          0.          0.          0.28867513\n",
      "   0.28867513  0.          0.        ]\n",
      " [ 0.          0.5         0.5         0.          0.5         0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.5       ]]\n",
      "<type 'numpy.ndarray'>\n",
      "(5, 30)\n"
     ]
    }
   ],
   "source": [
    "print testspace.label\n",
    "print testspace.tdm.shape\n",
    "print testspace.tdm.todense()\n",
    "print type(testspace.tdm.data)\n",
    "# testspace.tdm.data = (testspace.tdm.data.flatten())\n",
    "# testspace.tdm.data.reshape(6,23)\n",
    "print testspace.tdm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#預測\n",
    "#計算分類精度：\n",
    "def metrics_result(actual,predict):\n",
    "    print '精度:{0:.3f}'.format(metrics.precision_score(actual,predict,average='macro'))  \n",
    "    print '召回:{0:0.3f}'.format(metrics.recall_score(actual,predict,average='macro'))  \n",
    "    print 'f1-score:{0:.3f}'.format(metrics.f1_score(actual,predict,average='macro'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 30)\n",
      "(5, 30)\n",
      "<type 'list'> ['a', 'a', 'b', 'b', 'c', 'c']\n",
      "<type 'numpy.ndarray'> (6,)\n",
      "['tnews1', 'tnews2', 'tnews4', 'tnews3', 'tnews5']\n"
     ]
    }
   ],
   "source": [
    "# 導入訓練集\n",
    "trainpath = \"tfdifspace.dat\"\n",
    "train_set = readbunchobj(trainpath)\n",
    "\n",
    "# 導入測試集\n",
    "testpath = \"testspace.dat\"\n",
    "test_set = readbunchobj(testpath)\n",
    "\n",
    "xlabel = np.array(train_set.label)\n",
    "\n",
    "print train_set.tdm.shape\n",
    "print test_set.tdm.shape\n",
    "print type(train_set.label), train_set.label\n",
    "print type(xlabel), xlabel.shape\n",
    "print test_set.contentnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tnews2 實際類別: c  -->預測類別: b\n",
      "tnews4 實際類別: b  -->預測類別: a\n",
      "tnews5 實際類別: c  -->預測類別: b\n",
      "error rate: 60.0 %\n",
      "預測完畢!!!\n",
      "準確率： 0.4\n",
      "精度:0.278\n",
      "召回:0.500\n",
      "f1-score:0.356\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 應用樸素貝葉斯算法 \n",
    "# 1. 輸入詞袋向量和分類標籤\n",
    "#alpha 平滑參數:0.001 alpha越小，迭代次數越多，精度越高\n",
    "\n",
    "clf = MultinomialNB(alpha = 0.001).fit(train_set.tdm, train_set.label)\n",
    "\n",
    "predicted = clf.predict(test_set.tdm)\n",
    "total = len(predicted);rate = 0\n",
    "for flabel,contentname,expct_cate in zip(test_set.label,test_set.contentnames,predicted):\n",
    "    if flabel != expct_cate:\n",
    "        rate += 1\n",
    "        print contentname,\"實際類別:\",flabel,\" -->預測類別:\",expct_cate\n",
    "# 精度\n",
    "print \"error rate:\",float(rate)*100/float(total),\"%\"\n",
    "print \"預測完畢!!!\"\n",
    "\n",
    "print \"準確率：\", accuracy_score(test_set.label,predicted)\n",
    "metrics_result(test_set.label,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
